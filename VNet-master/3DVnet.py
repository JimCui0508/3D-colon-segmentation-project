# -*- coding: utf-8 -*-
"""3DUnet_BraTS2019_colab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C0-djxJK1kp_qmLYPSC_CP0U69u46BxS
"""

#Code sourced from following links
#https://github.com/sarthak25/Brain-tumor-segmentation
#https://github.com/karolzak/keras-unet/tree/master/keras_unet
#https://github.com/MohamedAliHabib/Brain-Tumor-Detection
#https://github.com/charan223/Brain-Tumor-Segmentation-using-Topological-Loss
#https://github.com/sdsubhajitdas/Brain-Tumor-Segmentation
#https://github.com/Mehrdad-Noori/Brain-Tumor-Segmentation
#https://github.com/yunyuntsai/BraTS-brain-tumer-segmentation/blob/master/Seg_net.ipynb

import tensorflow as tf
tf.compat.v1.disable_eager_execution()
from keras.models import Model
from keras.layers import Dense, Dropout, Activation, Flatten, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Conv3D, MaxPooling3D, Conv3DTranspose
from keras.layers import Input, merge, UpSampling2D,BatchNormalization
from keras.callbacks import ModelCheckpoint
#from keras.optimizers import adam_v2 as Adam
#from keras import optimizer_v2.adam.Adam as Adam
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras import backend as K
#from keras.utils import multi_gpu_model
#import tensorflow as tf
import os
import SimpleITK as sitk
import matplotlib.pyplot as plt
import skimage.io as io
from glob import glob
from Vnet_3d import Vnet_3d

#import cupy as np
import numpy as np
import random as r
import cv2

#from vnet import vnet

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "5,6,7"
config = tf.ConfigProto()
#config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 每个GPU上限控制在90%以内
session = tf.Session(config=config)
'''
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        # Currently, memory growth needs to be the same across GPUs
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
 #           tf.config.experimental.set_virtual_device_configuration(
  #      gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2560)])
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
    except RuntimeError as e:
        # Memory growth must be set before GPUs have been initialized
        print(e)
'''
#os.environ["CUDA_VISIBLE_DEVICES"] = "4,5,6,7"

path = "/home/public/CTC_ReconResults/zip_files/"


origin_files = glob(path+"/1.3.6.1.4.1.9328.50.4.*/**/ResampledImgv2.nii.gz", recursive=True)
seg_files = glob(path+"/1.3.6.1.4.1.9328.50.4.*/**/ResampledMaskv2.nii.gz", recursive=True)


print(len(origin_files),len(seg_files))



"""# Convert to Array"""

first_img = io.imread(origin_files[1], plugin="simpleitk")

print(f"shape: {first_img.shape}")
print(f"dtype: {first_img.dtype}")

"""## Visualize Flair Image"""




"""## Visualize Segmented Image"""


seg_img = io.imread(seg_files[1], plugin="simpleitk")



"""# Convert to Array """
def standardize(image):

    standardized_image = np.zeros(image.shape)

  #
  
      # iterate over the `z` dimension
    for z in range(image.shape[0]):
      # get a slice of the image 
      # at channel c and z-th dimension `z`
        image_slice = image[z,:,:]

      # subtract the mean from image_slice
        centered = image_slice - np.mean(image_slice)
      
      # divide by the standard deviation (only if it is different from zero)
        if(np.std(centered)!=0):
            centered = centered/np.std(centered) 
      
      # update  the slice of standardized image
      # with the scaled centered and scaled image
        standardized_image[z, :, :] = centered
    return standardized_image

def to_array(path, end, label=False):

    # get locations
    files = glob(path+end, recursive=True)
    img_list = []
    
    r.seed(42)
    r.shuffle(files)
    
    for file in files:
        img = io.imread(file, plugin="simpleitk")
      #  img = np.asarray(img)
      #  img = standardize(img)
        # standardization
    #    img = (img-img.mean())/img.std()
     #   print("img:",img.shape)
        img_list.append(img)
  
    img_list = np.array(img_list)  
    img_list = img_list.reshape((-1,128,128,128))
        
    
  
    return img_list

"""### np.expand_dims()"""





"""# Applying the Function"""

train = to_array(path=path, end="/1.3.6.1.4.1.9328.50.4.*/**/ResampledImgv2.nii.gz")
print(f"shape: {train.shape}")
print(f"dtype: {train.dtype}")

seg = to_array(path=path, end="/1.3.6.1.4.1.9328.50.4.*/**/ResampledMaskv2.nii.gz", label=True)
print(f"dtype: {seg.dtype}")






#X_train = flair
train = np.expand_dims(train, axis=4)
seg = seg.astype("float32")
#print(X_train.shape)
#train = train.get()
#seg = seg.get()
'''
def dice_coef(y_true, y_pred, epsilon=0.00001):
    """
    Dice = (2*|X & Y|)/ (|X|+ |Y|)
         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))
    ref: https://arxiv.org/pdf/1606.04797v1.pdf
    
    """
    axis = (0,1,2,3)
    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon
    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon
    return K.mean((dice_numerator)/(dice_denominator))

def dice_coef_loss(y_true, y_pred):
    return 1-dice_coef(y_true, y_pred)
'''
def dice_coef(y_true, y_pred):
   # smooth = 0 
    smooth = 0.0005
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

from tensorflow.keras.metrics import binary_crossentropy
def dice_coef_loss(y_true, y_pred):
    return 1-dice_coef(y_true, y_pred)

#K.set_image_data_format('channels_last')
#model = multi_gpu_model(model, gpus=4)
input_img = Input((128, 128, 128, 1))
model = Vnet_3d(input_img,8,0.2,True)
#model = vnet(input_size=(64, 128, 128, 1))
model.compile(optimizer=Adam(learning_rate=1e-4), loss=dice_coef_loss, metrics=[dice_coef])
model.summary()
# Define callbacks.
checkpoint_cb = ModelCheckpoint(
    "3DUnet.h5", save_best_only=True
)
model.fit(train, seg, validation_split=0.25, batch_size=1, epochs=100, shuffle=True)

model.save_weights("vnet_model.h5")

plt.plot(model.history.history['loss'])

plt.plot(model.history.history['val_loss'])
plt.legend(['train', 'validation'], loc='upper right')
plt.ylim(0, 1)
plt.xlabel('epoch')
plt.ylabel('loss')
plt.title('model loss')
plt.show()





plt.plot(model.history.history['dice_coef'])
plt.plot(model.history.history['val_dice_coef'])
plt.title('dice score')
plt.ylim(0, 1)
plt.xlabel('epoch')
plt.ylabel('dice coefficient')
plt.legend(['train', 'validation'], loc='lower right')
plt.show()
'''
plt.plot(model.history.history['iou'])
plt.plot(model.history.history['val_iou'])
plt.ylim(0, 1)
plt.title('IoU')
plt.xlabel('epoch')
plt.ylabel('IoU score')
plt.legend(['train', 'validation'], loc='lower right')
plt.show()

plt.plot(model.history.history['recall'])
plt.plot(model.history.history['val_recall'])
plt.ylim(0, 1)
plt.title('Recall')
plt.xlabel('epoch')
plt.ylabel('Recall')
plt.legend(['train', 'validation'], loc='lower right')
plt.show()

plt.plot(model.history.history['precision'])
plt.plot(model.history.history['val_precision'])
plt.ylim(0, 1)
plt.title('Precision')
plt.xlabel('epoch')
plt.ylabel('Precision')
plt.legend(['train', 'validation'], loc='lower right')
plt.show()
'''


"""# PREDICTION"""
'''
plt.imshow(X_train[1000][0]);

#plt.imshow(seg[1000][0]);

expand_img = np.expand_dims(X_train[1000], axis=0)

pred = model.predict(expand_img)

"""## Visualize Prediction"""

plt.imshow(pred[0][0]);

x = 333

sample = np.expand_dims(X_train[x], axis=0)
pred = model.predict(sample)


fig = plt.figure(figsize=(17, 15))

plt.subplot(1,4,1)
plt.title("Input: Flair + T2")
plt.imshow(X_train[x][0], cmap="inferno")

#plt.subplot(1,4,2)
#plt.title("Segmentation")
#plt.imshow(seg[x][0], cmap="inferno")

plt.subplot(1,4,3)
plt.title("Prediction")
plt.imshow(pred[0][0], cmap="inferno");


'''
